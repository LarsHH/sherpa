<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../img/favicon.ico">
  <title>First steps - Hobbit</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "First steps";
    var mkdocs_page_input_path = "first_steps.md";
    var mkdocs_page_url = "/first_steps/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Hobbit</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">Home</a>
	    </li>
          
            <li class="toctree-l1 current">
		
    <a class="current" href="./">First steps</a>
    <ul class="subnav">
            
    <li class="toctree-l2"><a href="#first-steps">First Steps</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#the-hyperparameters">The Hyperparameters</a></li>
        
            <li><a class="toctree-l3" href="#the-model">The model</a></li>
        
        </ul>
    

    <li class="toctree-l2"><a href="#the-dataset">The dataset</a></li>
    
        <ul>
        
            <li><a class="toctree-l3" href="#hyperband">Hyperband</a></li>
        
            <li><a class="toctree-l3" href="#running">Running</a></li>
        
            <li><a class="toctree-l3" href="#results">Results</a></li>
        
            <li><a class="toctree-l3" href="#using-a-generator">Using a Generator</a></li>
        
        </ul>
    

    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../hyperband/">Hyperband</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../hyperparameter/">Hyperparameters</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Hobbit</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>First steps</li>
    <li class="wy-breadcrumbs-aside">
      
        <a href="http://github.com/hobbit-ai/hobbit/edit/master/docs/first_steps.md"
          class="icon icon-github"> Edit on GitHub</a>
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="first-steps">First Steps</h1>
<p>In this tutorial we will write the code to train a shallow neural network to predict handwritten digits from the MNIST dataset using Keras and optimize it's hyperparameters using Hobbit.</p>
<h2 id="the-hyperparameters">The Hyperparameters</h2>
<p>First we need to define distributions and ranges for the hyperparameters we want to include in our model training. To do this we define a list of Hyperparameter objects, each one of these will be tuned afterwards. For each Hyperparameter we must assign a <code>name</code>, a tuple with the range of values to explore (<code>args</code>) and a <code>distribution</code> which indicates how to sample values within the defined range.</p>
<p>In this example we want to optimize three hyperparameters: the dropout rate, the activation function and the learning rate. We use uniform(0, 1) for the dropout rate, a discrete distribution over <code>('sigmoid', 'tanh', 'relu')</code> for the activation and a log-uniform for the learning rate. The log-uniform distribution samples uniformly on the log scale and then transforms back. You can see more information about the available distributions <a href="https://github.com/LarsHH/hobbit/blob/master/hobbit/hparam_generators.py">here</a>.</p>
<pre><code class="python">from hobbit import Hyperparameter
my_hparam_ranges = [Hyperparameter(name='learning_rate', distribution='log-uniform', distr_args=(0.0001, 0.1)),
                    Hyperparameter(name='activation', distribution='choice', distr_args=[('sigmoid', 'tanh', 'relu')]),
                    Hyperparameter(name='dropout', distribution='uniform', distr_args=(0., 1.))]
</code></pre>

<h2 id="the-model">The model</h2>
<p>With the principle of keeping Hobbit flexible we completely define the model we want to train inside a function which we call <code>my_model()</code>. This function takes a <strong>dictionary of hyperparameters</strong> <code>hparams</code> as its only argument and returns a <strong>compiled Keras model</strong>. Every model we train will follow this template and they will differ only in the values of the hyperparameters and how long they were trained.</p>
<p>Every optimizable hyperparameter within <code>my_model()</code> corresponds to one of the values defined before as a Hyperparameter object. Here we will specify where each hyperparameter goes and we will access it from the <code>hparams</code> dictionary like this 
<code>hparams['name_of_hyperparam']</code></p>
<pre><code class="python">import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop

def my_model(hparams):
    model = Sequential()
    model.add(Dropout(rate=hparams['dropout'], input_shape=(784,)))
    model.add(Dense(100, activation=hparams['activation']))
    model.add(Dropout(rate=hparams['dropout']))
    model.add(Dense(10, activation='softmax'))
    model.compile(loss='categorical_crossentropy',
                  optimizer=RMSprop(lr=hparams['learning_rate']),
                  metrics=['accuracy'])
    return model
</code></pre>

<h1 id="the-dataset">The dataset</h1>
<p>The training and validation datasets are loaded as a tuple of training and a tuple of validation data, respectively. These objects are usually numpy arrays with each sample as a row and each column as a feature. If there is some preprocessing for the data it has to be done before passing it to Hobbit. Here we load the MNIST dataset using Keras and do some simple preprocessing.</p>
<pre><code class="python">num_classes = 10

# the data, shuffled and split between train and test sets
(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(60000, 784)
x_test = x_test.reshape(10000, 784)
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

# convert class vectors to binary class matrices
y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)
y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)

my_dataset = (x_train, y_train)
my_validation_data = (x_test, y_test)
</code></pre>

<h2 id="hyperband">Hyperband</h2>
<p>We have all the ingredients. Now we just need to create the algorithm. As an argument you need to specify a repository directory. This is where Hobbit will store all of your models and the table with the results.</p>
<pre><code class="python">from hobbit.algorithms import Hyperband
hband = Hyperband(model_function=my_model,
                  dataset=my_dataset,
                  hparam_ranges=my_hparam_ranges,
                  repo_dir='./my_test_repo',
                  validation_data=my_validation_data)
</code></pre>

<h2 id="running">Running</h2>
<p>Finally, let's run the complete pipeline. Hyperband has two parameters:
<em> <strong>R</strong>: The budget of epochs per stage
</em> <strong>eta</strong>: The cut-factor after each stage and which is also the factor by which training gets longer at every stage. For eta the theory-default is 3</p>
<p>To give you a feel for these here is an example for R=20 and eta=3. Here n_i is the number of configurations and r_i the number of epochs they are trained for. Hyperband makes multiple runs in which it does successive halving. smax corresponds to the current run.</p>
<pre><code>R = 20
eta = 3

smax=2
n_0=9   r_0=2.22=2
n_1=3   r_1=6.66=7
n_2=1   r_2=20

smax=1
n_0=5   r_0=6.66=7
n_1=1   r_1=20

smax=0
n_0=3   r_0=20
</code></pre>
<p>Now let's run our own Hyperband. If you're on a CPU this may take a few minutes.</p>
<pre><code class="python">tab = hband.run(R=20, eta=3)
</code></pre>

<h2 id="results">Results</h2>
<p>To access the results for all configurations and their respective test error you can either use the returned Pandas dataframe from the <code>run()</code> function or look at the CSV in your repository directory. Val Loss indicates the lowest seen validation loss for the configuration. The <strong>Run</strong> corresponds to the specific run it was trained at according to the Hyperband algorithm with run zero being the last and longest one. The <strong>ID</strong> is an identifier of the model within the run.</p>
<pre><code class="python">tab
</code></pre>

<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Hparams</th>
      <th>ID</th>
      <th>Run</th>
      <th>Val Loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2-0</th>
      <td>{'learning_rate': 0.0013383297653888713, 'acti...</td>
      <td>0</td>
      <td>2</td>
      <td>0.079573</td>
    </tr>
    <tr>
      <th>2-1</th>
      <td>{'learning_rate': 0.00012199066883461425, 'act...</td>
      <td>1</td>
      <td>2</td>
      <td>0.504462</td>
    </tr>
    <tr>
      <th>2-2</th>
      <td>{'learning_rate': 0.00012022855306991257, 'act...</td>
      <td>2</td>
      <td>2</td>
      <td>0.361248</td>
    </tr>
    <tr>
      <th>2-3</th>
      <td>{'learning_rate': 0.01711893606634988, 'activa...</td>
      <td>3</td>
      <td>2</td>
      <td>0.110820</td>
    </tr>
    <tr>
      <th>2-4</th>
      <td>{'learning_rate': 0.0002600277942901727, 'acti...</td>
      <td>4</td>
      <td>2</td>
      <td>0.442517</td>
    </tr>
    <tr>
      <th>2-5</th>
      <td>{'learning_rate': 0.0004934370333196648, 'acti...</td>
      <td>5</td>
      <td>2</td>
      <td>0.287478</td>
    </tr>
    <tr>
      <th>2-6</th>
      <td>{'learning_rate': 0.007947367908290915, 'activ...</td>
      <td>6</td>
      <td>2</td>
      <td>1.002379</td>
    </tr>
    <tr>
      <th>2-7</th>
      <td>{'learning_rate': 0.000491890405781265, 'activ...</td>
      <td>7</td>
      <td>2</td>
      <td>0.280827</td>
    </tr>
    <tr>
      <th>2-8</th>
      <td>{'learning_rate': 0.0004272030665166832, 'acti...</td>
      <td>8</td>
      <td>2</td>
      <td>0.124675</td>
    </tr>
    <tr>
      <th>1-0</th>
      <td>{'learning_rate': 0.07198931288293847, 'activa...</td>
      <td>0</td>
      <td>1</td>
      <td>0.219331</td>
    </tr>
    <tr>
      <th>1-1</th>
      <td>{'learning_rate': 0.003255907153272381, 'activ...</td>
      <td>1</td>
      <td>1</td>
      <td>0.211909</td>
    </tr>
    <tr>
      <th>1-2</th>
      <td>{'learning_rate': 0.007926538077878733, 'activ...</td>
      <td>2</td>
      <td>1</td>
      <td>1.420097</td>
    </tr>
    <tr>
      <th>1-3</th>
      <td>{'learning_rate': 0.000888230245206736, 'activ...</td>
      <td>3</td>
      <td>1</td>
      <td>0.126166</td>
    </tr>
    <tr>
      <th>1-4</th>
      <td>{'learning_rate': 0.0011125712920494182, 'acti...</td>
      <td>4</td>
      <td>1</td>
      <td>0.077499</td>
    </tr>
    <tr>
      <th>0-0</th>
      <td>{'learning_rate': 0.018609130883389842, 'activ...</td>
      <td>0</td>
      <td>0</td>
      <td>0.148289</td>
    </tr>
    <tr>
      <th>0-1</th>
      <td>{'learning_rate': 0.003873098175478602, 'activ...</td>
      <td>1</td>
      <td>0</td>
      <td>0.098997</td>
    </tr>
    <tr>
      <th>0-2</th>
      <td>{'learning_rate': 0.0028061040541777402, 'acti...</td>
      <td>2</td>
      <td>0</td>
      <td>0.410078</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="using-a-generator">Using a Generator</h2>
<p>Let's say you want to stream data using a generator. In that case you need to pass the function that returns a generator (not the generator object itself) to <code>generator_function</code>. You can pass a tuple if you need two different generator functions for training and testing. If they are just different by their arguments you can pass the relevant arguments via <code>train_gen_args</code> and <code>valid_gen_args</code> which accept either a dictionary or list/tuple. Hobbit also needs the number of steps / batches in training / testing. You pass these via <code>steps_per_epoch</code> and <code>validation_steps</code> similarly as in Keras.</p>
<pre><code class="python">def example_generator(x, y, batch_size=100):
    num_samples = y.shape[0]
    num_batches = np.ceil(num_samples/batch_size).astype('int')
    while True:
        for i in range(num_batches):
            from_ = i*batch_size
            to_ = min((i+1)*batch_size, num_samples)
            yield x[from_:to_], y[from_:to_]
</code></pre>

<p>Then set up Hyperband:</p>
<pre><code class="python">hband = Hyperband(model_function=my_model,
                  hparam_ranges=my_hparam_ranges,
                  repo_dir='./my_test_repo',
                  generator_function=example_generator,
                  train_gen_args=(x_train, y_train, 100),
                  valid_gen_args=(x_test, y_test, 100),
                  steps_per_epoch=x_train.shape[0]//100,
                  validation_steps=x_test.shape[0]//100)
</code></pre>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../hyperband/" class="btn btn-neutral float-right" title="Hyperband">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href=".." class="btn btn-neutral" title="Home"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>
    
  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="http://github.com/hobbit-ai/hobbit" class="fa fa-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href=".." style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../hyperband/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>
    <script src="../js/theme.js"></script>

</body>
</html>
